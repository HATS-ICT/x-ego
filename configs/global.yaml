meta:
  seed: 42

# Task configuration (for Stage 2 linear probing)
# These are defaults, override in task-specific configs
task:
  task_id: null
  ml_form: null
  num_classes: null
  output_dim: null
  label_column: null

data:
  partition: all # train, val, test, all
  labels_folder: labels
  video_folder: video_544x306_30fps
  persistent_workers: true
  pin_mem: true
  batch_size: 64
  num_workers: 0
  prefetch_factor: 2
  data_path_csv_filename: video_partitioned_chunked_downsized.csv
  fixed_duration_seconds: 5
  target_fps: 4
  video_column_name: video_path
  video_processor_model: facebook/vjepa2-vitl-fpc16-256-ssv2
  video_size_mode: resize_distort
  num_pov_agents: 5  # Number of agents from team side to use for inference (1-5, recommend 5 for full team)
                     # When contrastive learning is enabled, dataset always samples 5 agents,
                     # then model randomly selects num_pov_agents from these 5 for inference
  mask_minimap: true
  time_jitter_max_seconds: 0.3  # Maximum random time jitter (Â±seconds) applied to each sampled frame for temporal augmentation. Set to 0 to disable.
  use_precomputed_embeddings: true  # If true, load pre-computed embeddings instead of videos
                                     # MEMORY OPTIMIZATION: Video encoder will NOT be initialized, saving ~300-500MB memory and checkpoint size
  precomputed_embeddings_encoder: ${model.encoder.video.model_type}
  # Contrastive learning (Stage 1) settings
  allow_variable_agents: false  # If true, allow samples with less than 5 agents (dead teammates)
  min_agents: 2  # Minimum number of agents required per sample when allow_variable_agents=true


model:
  activation: gelu
  num_pov_agents: ${data.num_pov_agents}
  num_target_agents: 5
  team_embed_dim: 32
  hidden_dim: 256
  num_hidden_layers: 3
  dropout: 0.1
  class_weights: null  # Options: null, inverse, inverse_sqrt, effective_num, pos_weight
  # Stage 2 linear probing settings
  stage1_checkpoint: null  # Path to Stage 1 contrastive checkpoint
  freeze_encoder: false    # Whether to freeze encoder (video projector) weights
  agent_fusion:
    method: concat  # Options: "mean", "max", "attention", "concat"
    fused_agent_dim: 768
    num_attn_heads: 8 # only when method is attention
    num_layers: 2
  loss_fn: bce  # Options: bce, focal
  focal:
    alpha: 0.25  # Class balance weight for positive class
    gamma: 2.0  # Focusing parameter (higher = more focus on hard examples)
  encoder:
    video:
      freeze_backbone: true
      model_type: dinov2  # Options: clip, dinov2, siglip, vivit, videomae, vjepa2
    proj_dim: ${model.agent_fusion.fused_agent_dim}
  contrastive:
    enable: true
    logit_scale_init: 10  # Temperature parameter (pass actual value, not log)
    logit_bias_init: -3   # Bias parameter (pass actual value)
    turn_off_bias: false   # If true, no bias is applied (for SigLIP ablation setup 1: b=n/a)
    # SigLIP ablation configurations:
    # Setup 1: logit_scale_init=10, logit_bias_init=0,   turn_off_bias=true  (b: n/a,  t: log10)
    # Setup 2: logit_scale_init=10, logit_bias_init=-10, turn_off_bias=false (b: -10,  t: log10)
    # Setup 3: logit_scale_init=1,  logit_bias_init=-10, turn_off_bias=false (b: -10,  t: log1)
    # Setup 4: logit_scale_init=10, logit_bias_init=0,   turn_off_bias=false (b: 0,    t: log10)
    # Setup 5: logit_scale_init=1,  logit_bias_init=0,   turn_off_bias=false (b: 0,    t: log1)
    loss_weight: 1.0


training:
  max_epochs: 40  # Total training epochs
  max_steps: -1  # Disabled when using max_epochs
  accelerator: gpu
  devices: 1
  strategy: auto
  precision: bf16-mixed
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  val_check_interval: null  # Disabled when using check_val_every_n_epoch
  check_val_every_n_epoch: 1  # Validate at the end of each epoch
  log_every_n_steps: 10
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  torch_compile: false
  deterministic: false
  num_sanity_val_steps: 0
  limit_train_batches: 1.0 # 1.0 means use all data
  limit_val_batches: 1.0
  limit_test_batches: 1.0


optimization:
  lr: 0.0003
  weight_decay: 0.01
  fused_optimizer: true  # Enable fused AdamW and disable gradient clipping

wandb:
  enabled: true
  project: xego

checkpoint:
  epoch:
    filename: ${meta.run_name}-e{epoch:02d}-s{step:06d}-l{val/loss:.4f}
    monitor: 'val/loss'
    mode: min
    save_top_k: 1  # Save the best checkpoint based on validation loss
    save_last: true  # Also save the last checkpoint
    auto_insert_metric_name: false
    save_on_train_epoch_end: true
    every_n_epochs: 1  # Checkpoint every epoch
  step:
    filename: ${meta.run_name}-s{step:06d}-e{epoch:02d}
    monitor: null
    mode: min
    save_top_k: 0  # Disabled: don't save step-based checkpoints
    save_last: false
    auto_insert_metric_name: false
    save_on_train_epoch_end: false
    every_n_train_steps: null  # Disabled: step-based checkpointing turned off
