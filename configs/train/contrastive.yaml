meta:
  seed: 42
  fast_dev_run: false
  resume_exp: null
  exp_name: ctfm-contrastive
  run_name: ctfm-contrastive

data:
  partition: all # all, recording, youtube
  youtube_partition: all # all, tournament, tutorial 
  youtube_folder: youtube_chunk
  trajectory_folder: trajectory
  transcription_folder: transcription_enhanced
  video_folder: video_544x306_30fps
  batch_size: 16
  num_workers: 10
  persistent_workers: false
  pin_mem: true
  prefetch_factor: 2
  data_path_csv_filename: video_path_partitioned_544x306_30fps.csv
  fixed_duration_seconds: 5
  target_fps: 4
  video_column_name: video_path
  seek_mode: exact  # Video seeking mode for torchcodec
  num_ffmpeg_threads: 0  # Number of FFmpeg threads for video decoding
  video_size_mode: resize_distort
  audio_sample_rate: 16000  # Whisper expects 16kHz audio
  audio_num_channels: 1
  sample_audio_with_team_voice: true  # Whether to mix team voice audio with game audio
  team_voice_audio_clip_weight: 1.0  # Weight for team voice audio in mixing
  recording_text_trajectory_weight: 0.5  # Weight for trajectory-based descriptions
  recording_text_transcription_weight: 0.5  # Weight for voice transcriptions
  max_text_per_clip: 3
  mask_minimap: false
  communication_types_to_exclude:
    - emotional_social
    - noise_artifacts

model:
  modalities:
    - video
    - text
    # - audio
  encoder:
    video:
      from_scratch: false
      scratch_setting:
        patch_size: 16
        crop_size: 224
        frames_per_clip: 20
        tubelet_size: 2
        hidden_size: 1024
        in_chans: 3
        num_attention_heads: 16
        num_hidden_layers: 12
        drop_path_rate: 0.0
        mlp_ratio: 4.0
        layer_norm_eps: 1e-6
        qkv_bias: true
        attention_probs_dropout_prob: 0.0
        initializer_range: 0.02
        attention_dropout: 0.0
        pooling: mean
      proj_after_pooling: true
      pooling: 'attentive'
      freeze_backbone: true
      from_pretrained: facebook/vjepa2-vitl-fpc16-256-ssv2
      processor_model: facebook/vjepa2-vitl-fpc16-256-ssv2
      skip_projection: false
    audio:
      backbone: 'whisper'
      freeze_backbone: true
      pooling: 'mean'
      proj_after_pooling: false
      from_pretrained: 'openai/whisper-base'
      processor_model: openai/whisper-base
    text:
      backbone: 'siglip-text'
      freeze_backbone: true
      pooling: 'eos'
      proj_after_pooling: true
      from_pretrained: google/siglip-base-patch16-224
      processor_model: google/siglip-base-patch16-224

training:
  max_epochs: 20
  accelerator: gpu
  devices: 1
  strategy: auto
  precision: bf16
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  val_check_interval: null
  check_val_every_n_epoch: 1
  log_every_n_steps: 50
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  torch_compile: false
  deterministic: false
  num_sanity_val_steps: 0
  limit_train_batches: 1.0 # 1.0 means use all data
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  contrastive:
    style: siglip # clip, siglip
    use_symmetric_loss: false # Enable symmetric loss
    project_to_shared_dim: 768 # Project to shared dimension
    do_projection: true # Enable projection layers
    logit_temp_init: 2.302585 # Natural Log of 10, Initial value for logit temperature parameter
    logit_bias_init: -10 # Initial value for logit bias parameter
    loss_weights:
      audio_video: 1.0
      video_audio: 1.0
      text_audio: 1.0
      audio_text: 1.0
      text_video: 1.0
      video_text: 1.0


optimization:
  lr: 0.0003
  weight_decay: 0.01
  fused_optimizer: true  # Enable fused AdamW and disable gradient clipping

wandb:
  enabled: true
  project: ctfm
  tags: ['${meta.exp_name}']
  notes: 'CTFM contrastive learning training'

checkpoint:
  epoch:
    filename: ${meta.run_name}-e{epoch:02d}-s{step:06d}-l{val/loss_total:.4f}
    monitor: 'val/loss_total'
    mode: 'min'
    save_top_k: -1  # Save all checkpoints (every epoch)
    save_last: true
    auto_insert_metric_name: false
    save_on_train_epoch_end: true
    every_n_epochs: 1
  step:
    filename: ${meta.run_name}-s{step:06d}-e{epoch:02d}
    monitor: null  # No monitoring for step-based saves
    mode: 'min'
    save_top_k: -1  # Save all step checkpoints
    save_last: false  # Don't duplicate last checkpoint
    auto_insert_metric_name: false
    save_on_train_epoch_end: false
    every_n_train_steps: 1000
