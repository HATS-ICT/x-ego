# Stage 1: Contrastive Learning Only (Team Alignment)

meta:
  seed: 42
  run_name: contrastive-${model.encoder.model_type}
  resume_exp: null

data:
  partition: all
  labels_folder: labels
  video_folder: video_306x306_4fps
  persistent_workers: true
  pin_mem: true
  batch_size: 16
  num_workers: 10
  prefetch_factor: 2
  data_path_csv_filename: video_partitioned_chunked_downsized.csv
  fixed_duration_seconds: 5
  target_fps: 4
  video_column_name: video_path
  ui_mask: all  # options: none, minimap_only, all
  random_mask:
    enable: true  # enable random tube masking (applied consistently across all frames)
    num_tubes: 3  # number of random rectangular tubes to mask
    min_size_ratio: 0.15  # minimum tube size as ratio of frame dimensions
    max_size_ratio: 0.35  # maximum tube size as ratio of frame dimensions (target ~30-70% total masked area)
  time_jitter_max_seconds: 0
  labels_filename: contrastive.csv

model:
  activation: gelu
  encoder:
    finetune_last_k_layers: 3  # -1: finetune all, 0: freeze all, k: finetune last k layers
    model_type: siglip2 # options: siglip2, dinov2, clip, vivit, videomae, vjepa2
  projector:
    proj_dim: 768
    num_hidden_layers: 1
  contrastive:
    enable: true
    logit_scale_init: 10
    logit_bias_init: -3
    turn_off_bias: false
    loss_weight: 1.0
  reconstruction:
    enable: false  # enable video reconstruction auxiliary loss
    loss_weight: 0.001  # lambda scaling factor (start small, e.g., 0.001)
    target_frame_size: 64  # reconstruct to smaller resolution for efficiency
    num_reconstruct_frames: 4  # number of frames to reconstruct (temporally sampled)
    # Transformer decoder settings
    d_model: 512  # transformer hidden dimension
    n_heads: 8  # number of attention heads
    depth: 4  # number of transformer layers
    n_latents: 1  # number of latent tokens
    patch_size: 8  # patch size for reconstruction
    dropout: 0.0  # dropout rate
    mlp_ratio: 4.0  # MLP hidden dimension ratio
    time_every: 2  # apply temporal attention every N layers

training:
  max_epochs: 40
  max_steps: -1
  accelerator: gpu
  devices: 1
  strategy: auto
  precision: bf16-mixed
  gradient_clip_val: 1.0
  accumulate_grad_batches: 4
  val_check_interval: null
  check_val_every_n_epoch: 1
  log_every_n_steps: 10
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  torch_compile: true
  deterministic: false
  num_sanity_val_steps: 0
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0

optimization:
  lr: 0.0001
  weight_decay: 0.01
  fused_optimizer: true
  scheduler:
    type: cosine
    warmup_steps: 500
    min_lr_ratio: 0.1  # final_lr = min_lr_ratio * lr

wandb:
  enabled: true
  project: xego-v2
  name: null
  group: null
  tags: null
  notes: null
  save_dir: null

checkpoint:
  epoch:
    filename: ${meta.run_name}-e{epoch:02d}-s{step:06d}-l{val/contrastive_loss:.4f}
    monitor: 'val/contrastive_loss'
    mode: min
    save_top_k: -1  # -1 saves all checkpoints at every epoch
    save_last: true
    auto_insert_metric_name: false
    save_on_train_epoch_end: true
    every_n_epochs: 1
  step:
    filename: ${meta.run_name}-s{step:06d}-e{epoch:02d}
    monitor: null
    mode: min
    save_top_k: 0
    save_last: false
    auto_insert_metric_name: false
    save_on_train_epoch_end: false
    every_n_train_steps: null
