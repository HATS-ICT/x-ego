# Stage 2: Linear Probing on Downstream Tasks
# Uses single-agent video input with frozen encoder

meta:
  seed: 42
  run_name: probe-${task.task_id}-${model.encoder.model_type}
  resume_exp: null

task:
  task_id: self_location_0s
  ml_form: multi_cls
  num_classes: 23
  output_dim: 23
  label_column: place

data:
  partition: all
  labels_folder: labels
  video_folder: video_306x306_4fps
  persistent_workers: true
  pin_mem: true
  batch_size: 16
  num_workers: 16
  prefetch_factor: 2
  data_path_csv_filename: video_partitioned_chunked_downsized.csv
  fixed_duration_seconds: 5
  target_fps: 4
  video_column_name: video_path
  ui_mask: all  # options: none, minimap_only, all (all not implemented yet)
  time_jitter_max_seconds: 0

model:
  activation: gelu
  # Stage 1 checkpoint path - set to null for baseline (off-the-shelf HuggingFace)
  # Set to checkpoint path to use pretrained encoder from contrastive learning
  stage1_checkpoint: null
  encoder:
    finetune_last_k_layers: 0  # -1: finetune all, 0: freeze all, k: finetune last k layers
    model_type: siglip2

training:
  max_epochs: 30
  max_steps: -1
  accelerator: gpu
  devices: 1
  strategy: auto
  precision: bf16-mixed
  gradient_clip_val: 1.0
  accumulate_grad_batches: 2
  val_check_interval: null
  check_val_every_n_epoch: 1
  log_every_n_steps: 10
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  torch_compile: false
  deterministic: false
  num_sanity_val_steps: 0
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0

optimization:
  lr: 0.0004
  weight_decay: 0.0
  fused_optimizer: true

wandb:
  enabled: true
  project: xego-v2
  name: ${meta.run_name}
  group: null
  tags:
  - ${task.task_id}
  - ${model.encoder.model_type}
  - downstream
  - ui_mask_${data.ui_mask}
  notes: null
  save_dir: null

checkpoint:
  epoch:
    filename: ${meta.run_name}-e{epoch:02d}-l{val/loss:.4f}
    monitor: 'val/loss'
    mode: min
    save_top_k: 1
    save_last: true
    auto_insert_metric_name: false
    save_on_train_epoch_end: true
    every_n_epochs: 1
  step:
    filename: ${meta.run_name}-s{step:06d}-e{epoch:02d}
    monitor: null
    mode: min
    save_top_k: 0
    save_last: false
    auto_insert_metric_name: false
    save_on_train_epoch_end: false
    every_n_train_steps: null
